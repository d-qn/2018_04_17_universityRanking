threeR <- full_join(
full_join(qtmp, ttmp),
left_join(stmp, ttmp)
)  %>%
mutate(
qs_rank = rank2int(qs_rank),
ti_rank = rank2int(ti_rank),
sh_rank = rank2int(sh_rank)
)
threeR$name <- ifelse(!is.na(threeR$qs_name), threeR$qs_name,
ifelse(!is.na(threeR$ti_name), threeR$ti_name, threeR$sh_name))
stopifnot(all(!is.na(threeR$name)))
threeR$country <- ifelse(!is.na(threeR$qs_country), threeR$qs_country,
ifelse(!is.na(threeR$ti_country), threeR$ti_country, threeR$sh_country))
stopifnot(all(!is.na(threeR$country)))
threeR %<>%
select(-qs_name, -qs_country, -ti_name, -ti_country, -sh_name, -sh_country) %>%
select(name, country, everything())
threeRtop <- threeR %>%
select(name, country, qs_rank, ti_rank, sh_rank, everything()) %>%
mutate(
sum3R = ifelse(is.na(qs_rank), 0, qs_rank)  + ifelse(is.na(ti_rank), 0, ti_rank)  + ifelse(is.na(sh_rank), 0, sh_rank),
nonNA3R = is.na(qs_rank) + is.na(ti_rank) + is.na(sh_rank),
rank = sum3R / (3-nonNA3R)
) %>%
arrange(rank)
threeRtop %>% write_csv("data/threeRanking_merged_pre.csv")
## edit that file by hand in libre office!
threeRtop %>% filter(nonNA3R > 0) %>% head(20)
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
# UCL fix
threeRtop[which(threeRtop$name == 'UCL'),'ti_rank'] <- 16
threeRtop
threeRtop %>%
mutate(
sum3R = ifelse(is.na(qs_rank), 0, qs_rank)  + ifelse(is.na(ti_rank), 0, ti_rank)  + ifelse(is.na(sh_rank), 0, sh_rank),
nonNA3R = is.na(qs_rank) + is.na(ti_rank) + is.na(sh_rank),
rank = sum3R / (3-nonNA3R)
) %>%
arrange(rank)
threeRtop
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
threeRtop
threeRtop[which(threeRtop$name == 'UCL'),'ti_rank'] <- 16
ti
ti_table
head(ti_table, 20
)
7 + 16 + 16
39 / 3
scrapeData <- F
openRefineExport <- F
geocodeData <- F
qsLocalUrl <- 'data/QS World University Rankings 2018 _ Top Universities.htm'
qsLocalUrlCountry <- 'data/QS World University Rankings 2018 _ Top Universities_ranking.htm'
timesUrl <- 'https://www.timeshighereducation.com/world-university-rankings/2018/world-ranking#!/page/0/length/-1/sort_by/rank/sort_order/asc/cols/stats'
shangaiUrl1 <- 'http://www.shanghairanking.com/ARWU2017.html'
shangaiUrl2 <- 'http://www.shanghairanking.com/ARWU2017Candidates.html'
cleanOutput <- F
require(lintr)
library(tidyverse)
library(magrittr)
library(stringr)
library(knitr)
library(countrycode)
library(swiMap)
library(swiTheme)
### Getting data in packages
library(rvest)
library(skimr)
library(readxl)
# helper: write out a script phantomjs can process
renderJS_page <- function(url, file = "scrape.js") {
writeLines(sprintf("var page = require('webpage').create();
page.open('%s', function () {
console.log(page.content); //page source
phantom.exit();
});", url), con = file)
}
if(scrapeData) {
## 1. get QS indicators
qs_table <- read_html(qsLocalUrl) %>%
html_nodes("table#qs-rankings-indicators") %>%
html_table()
# some ranking are NA, remove them
qs_table <- qs_table[[1]] %>%
rename(qs_rank = `# RANK20182017201620152018`) %>%
filter(qs_rank != 'N/A')
countries <- read_html(qsLocalUrlCountry) %>%
html_nodes("table#qs-rankings") %>%
html_nodes(".country div img") %>%
html_attr("data-original-title")
unis <- read_html(qsLocalUrlCountry) %>%
html_nodes("table#qs-rankings") %>%
html_nodes(".uni div") %>%
html_nodes(".title") %>%
html_text()
stopifnot(nrow(qs_table) == length(countries))
qs_table$country <- countries[match(qs_table$UNIVERSITY, unis)]
# qs_table$uni <- unis[match(qs_table$UNIVERSITY, unis)]
qs_table %<>% select(qs_rank, UNIVERSITY, country, everything())
# qs_table %<>% select(qs_rank, UNIVERSITY, country, uni, everything())
tmp <- read_html(qsLocalUrlCountry) %>%
html_nodes("table#qs-rankings") %>% html_table()
## 2 Times
# render the javacript page and save it
renderJS_page(timesUrl, "scrape_times.js")
system("~/swissinfo/phantomjs-2.1.1-macosx/bin/phantomjs scrape_times.js > scrape_times.html")
## note: run html_text on the table node, will result in a mess of text (unveristy name and country appended)
ti_table <- read_html("scrape_times.html") %>%
html_node("table") %>%
html_nodes ("tr") #%>%  html_children()
#ti_table %>% html_children()
ti_rank <- ti_table %>%
html_nodes(".rank.sorting_1.sorting_2") %>%
html_text()
ti_name <- ti_table %>%
html_nodes(".name.namesearch a") %>%
html_text()
# get rid of the apply caught
ti_name <- ti_name[which(!grepl("Apply", ti_name))]
ti_name <- matrix(ti_name, ncol = 3, byrow = T)[,1:2] %>%
as.tibble() %>%
rename(name = V1, country = V2)
ti_table <- cbind(ti_rank, ti_name) %>% as.tibble()
## 3 Shangai
scrapeShangaiRanking <- function(url) {
sh_tmp <- read_html(url) %>%
html_nodes("table") %>%
html_table(fill = T) %>%
.[[1]]
colnames(sh_tmp) <- c(
'sh_rank', 'name', 'V3', 'nationalRank', 'score',
'alumni', 'award', 'HiCi', 'N&S', 'PUB', 'PCP')
sh_table <- sh_tmp %>%
as.tibble() %>%
select(-V3)
# retrieve the country back
countries <-read_html(url) %>%
html_nodes("table tr") %>%
html_nodes("td a") %>%
html_attr("href")
idx <- str_detect(countries, pattern = "^World\\-University\\-Rankings\\-2017\\/")
countries <- str_replace(countries[idx], "^World\\-University\\-Rankings\\-2017\\/", "")
countries <- str_replace(countries, "\\-", " ") %>%
str_replace("\\.html", "")
stopifnot(nrow(sh_table) == length(countries))
sh_table$country = countries
sh_table
}
sh_table <- scrapeShangaiRanking(shangaiUrl1)
save(qs_table, ti_table, sh_table, file = "data/3rankingScraped.RData")
} else {
load("data/3rankingScraped.RData")
}
if(openRefineExport) {
# Prepare a data.frame of university names for open Refine
threeMessRankings <- bind_rows(list(
qs_table %>%
select(UNIVERSITY, country) %>%
rename(name = UNIVERSITY) %>%
mutate(key = 1:n(), source = "QS"),
ti_table %>%
select(name, country) %>%
mutate(key = 1:n(), source = "times"),
sh_table %>%
select(name, country) %>%
mutate(key = 1:n(), source = "Shangai")
))
write_csv(threeMessRankings, "data/threeMessRankings2OpenRefine_pre.csv")
} else {
or_rankings <- read_csv("data/threeMessRankings2OpenRefine_post.csv")
}
## Relabel university names based on Open Refine
qs_table$UNIVERSITY <- or_rankings %>%
filter(source == "QS") %>%
arrange(key) %>%
.$name
ti_table$name <- or_rankings %>%
filter(source == "times") %>%
arrange(key) %>%
.$name
sh_table$name <- or_rankings %>%
filter(source == "Shangai") %>%
arrange(key) %>%
.$name
## 1. Take only the top 500 for the 3 rankings!
if(geocodeData) {
library(ggmap)
qst <- qs_table %>%
filter(!qs_rank %in%
c('501-550', '551-600', '601-650', '651-700',
'701-750', '751-800', '801-1000')) %>%
# remove the abbrevation from the unversity names
mutate(UNIVERSITY = str_replace_all(UNIVERSITY, " \\(.*\\)$", ""))
nrow(qst)
ti_table %<>%
mutate(ti_rank = str_replace_all(ti_rank, "=", ""))
tit <- ti_table %>% filter(!ti_rank %in% c("501–600", "601–800", "801–1000", "1001+"))
#tit$ti_rank
nrow(tit)
#sh_table$sh_rank
nrow(sh_table)
## 2. geocode
# https://stackoverflow.com/questions/36175529/getting-over-query-limit-after-one-request-with-geocode?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
# -- need to install the devtools version of ggmap 2.7 and register API key, otherwise full of query limit errors!!!
register_google(key = "AIzaSyBGsMcsB0QKM2Mjxh-JvPPrn-5wm0KRr3o")
# a. QS init
qst$lon <- NA
qst$lat <- NA
i <- 1:nrow(qst)
geocodeQueryCheck()
res <- geocode(str_c(qst$UNIVERSITY[i], ", ", qst$country[i]), output = "latlon", source = "google", messaging = T)
qst[i,"lon"] <- res$lon
qst[i,"lat"] <- res$lat
# b TI init
tit$lon <- NA
tit$lat <- NA
i <- 1:nrow(tit)
geocodeQueryCheck()
res <- geocode(str_c(tit$name[i], ", ", tit$country[i]), output = "latlon", source = "google", messaging = T)
tit[i,"lon"] <- res$lon
tit[i,"lat"] <- res$lat
# c Shangai
sh_table$lon <- NA
sh_table$lat <- NA
i <- 1:nrow(sh_table)
geocodeQueryCheck()
res <- geocode(str_c(sh_table$name[i], ", ", sh_table$country[i]), output = "latlon", source = "google", messaging = T)
sh_table[i,"lon"] <- res$lon
sh_table[i,"lat"] <- res$lat
if(any(is.na(sh_table$lon))) {
i <- which(is.na(sh_table$lon))
res <- geocode(str_c(sh_table$name[i], ", ", str_replace(sh_table$country[i], " tw", "")), output = "latlon", source = "google", messaging = T)
sh_table[i,"lon"] <- res$lon
sh_table[i,"lat"] <- res$lat
}
save(qst, tit, sh_table, file = "input/3top500RankingRefinedGeocoded.RData")
} else {
load("input/3top500RankingRefinedGeocoded.RData")
}
## 2. R
c(qst$lon, tit$lon, sh_table$lon)
c(qst$lon, tit$lon, sh_table$lon) %>% unique() %>% length()
c(qst$lat, tit$lat, sh_table$lat)  %>% length()
c(qst$lat, tit$lat, sh_table$lat) %>% unique() %>% length()
qtmp <- qst %>%
select(qs_rank, UNIVERSITY, country, lon, lat) %>%
rename(qs_name = UNIVERSITY, qs_country = country) %>%
mutate(
qs_rank = str_replace_all(qs_rank, "^=", ""),
qs_key = 1:n()
)
stopifnot(all(!duplicated(qtmp$lon)))
ttmp <- tit %>%
rename(ti_name = name, ti_country = country) %>%
mutate(
ti_key = 1:n()
) %>%
as.data.frame()
# remove the duplicated entries, the 3 ones at the end
ttmp %<>% filter(!duplicated(lon))
stopifnot(all(!duplicated(ttmp$lon)))
stmp <- sh_table %>%
select(sh_rank, name, country, lon, lat) %>%
rename(sh_name = name, sh_country = country) %>%
mutate(
sh_key = 1:n()
) %>%
as.data.frame()
# remove the duplicated entries,
stmp %<>% filter(!duplicated(lon))
stopifnot(all(!duplicated(stmp$lon)))
rank2int <- function(ranks) {
idxInt <- which(str_detect(ranks, "^\\d+$"))
if(length(idxInt) > 0) {
ranks[idxInt] <- as.integer(ranks[idxInt])
}
# get the index of integer intervals
idxItl <- which(str_detect(ranks, "^\\d+\\-\\d+$"))
if(length(idxItl) > 0) {
rrange <- tibble(
rangeStart = str_extract(ranks[idxItl], "^\\d+") %>% as.integer(),
rangeEnd = str_extract(ranks[idxItl], "\\d+$") %>% as.integer()
)
ranks[idxItl] <- rowMeans(rrange)
}
as.numeric(ranks)
}
threeR <- full_join(
full_join(qtmp, ttmp),
left_join(stmp, ttmp)
)  %>%
mutate(
qs_rank = rank2int(qs_rank),
ti_rank = rank2int(ti_rank),
sh_rank = rank2int(sh_rank)
)
threeR$name <- ifelse(!is.na(threeR$qs_name), threeR$qs_name,
ifelse(!is.na(threeR$ti_name), threeR$ti_name, threeR$sh_name))
stopifnot(all(!is.na(threeR$name)))
threeR$country <- ifelse(!is.na(threeR$qs_country), threeR$qs_country,
ifelse(!is.na(threeR$ti_country), threeR$ti_country, threeR$sh_country))
stopifnot(all(!is.na(threeR$country)))
threeR %<>%
select(-qs_name, -qs_country, -ti_name, -ti_country, -sh_name, -sh_country) %>%
select(name, country, everything())
threeRtop <- threeR %>%
select(name, country, qs_rank, ti_rank, sh_rank, everything()) %>%
mutate(
sum3R = ifelse(is.na(qs_rank), 0, qs_rank)  + ifelse(is.na(ti_rank), 0, ti_rank)  + ifelse(is.na(sh_rank), 0, sh_rank),
nonNA3R = is.na(qs_rank) + is.na(ti_rank) + is.na(sh_rank),
rank = sum3R / (3-nonNA3R)
) %>%
arrange(rank)
threeRtop %>% write_csv("data/threeRanking_merged_pre.csv")
## edit that file by hand in libre office!
threeRtop %>% filter(nonNA3R > 0) %>% head(20)
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
# # UCL fix
# threeRtop[which(threeRtop$name == 'UCL'),'ti_rank'] <- 16
threeRtop %>%
mutate(
sum3R = ifelse(is.na(qs_rank), 0, qs_rank)  + ifelse(is.na(ti_rank), 0, ti_rank)  + ifelse(is.na(sh_rank), 0, sh_rank),
nonNA3R = is.na(qs_rank) + is.na(ti_rank) + is.na(sh_rank),
rank = sum3R / (3-nonNA3R)
) %>%
arrange(rank)
# reformat country name, label geo location (region)
threeRtop %<>%
mutate(
iso2 = countrycode(country, "country.name", "iso2c"),
country = countrycode(iso2, "iso2c", "country.name.en"),
region = countrycode(iso2, "iso2c", "region"),
continent = countrycode(iso2, "iso2c", "continent"),
invRank = 1/ rank,
intRank = round(rank),
rankGroup = cut(rank, breaks = c(0, 50, 100, 200, 300, 400, 500),
labels = c(' 0-50', ' 50-100', '100-200', '200-300', '300-400', '400-500'))
) %>%
select(-sum3R, -nonNA3R, -qs_key, -ti_key, -sh_key) %>%
# rename region
mutate(
region = case_when(
region == 'Eastern Asia' ~ 'East Asia',
region == 'Northern Africa' ~ 'North Africa',
region == 'Northern America' ~ 'North America',
region == 'South-Eastern Asia' ~ 'South East Asia' ,
region == 'Southern Asia' ~ 'South Asia' ,
region == 'Western Asia' ~ 'Middle East',
T ~ region
),
country = case_when(
country == 'United States of America' ~ 'USA',
country == 'United Kingdom of Great Britain and Northern Ireland' ~ 'UK',
T ~ country
)
)
threeRtop_500 <- threeRtop %>%
head(500)
# flourish export
threeRtop_500 %>%
mutate(keylocation = str_c("loc_", 1:n())) %>%
select(-lon, -lat)  %>%
write_csv("input/threeRtop500.csv", na ='')
# flourish geo lon lat data file
threeRtop_500 %>%
mutate(keylocation = str_c("loc_", 1:n())) %>%
select(lon, lat, keylocation, country, region, name) %>%
write_csv("input/threeRtop500_lonLat.csv")
# DW export table
threeRtop_500 %>%
write_csv("input/threeRtop500_dw.csv", na = '-')
# DW export map
threeRtop_500 %>%
select(lat, lon, everything(), -continent, -region, -intRank, -rankGroup) %>%
filter(!is.na(lon)) ->
threeRtop_500_map
bind_cols(
threeRtop_500_map,
countryTranslation(threeRtop_500_map$iso2, output = c("EN", "DE", "FR", "IT", "ES", "PT","RU", "ZH", "JA","AR"))
) %>%
select(-country, -iso2, -code) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric()) %>%
write_csv("input/threeRtop500_dwMap.csv", na = '-')
# make it long
threeRtop %>%
filter(!is.na(qs_rank), !is.na(ti_rank), !is.na(sh_rank)) %>%
head(50) %>%
select(-lon, -lat, -iso2, -region, invRank, -rankGroup) %>%
rename(`average rank` = rank) %>%
gather(key = ranking, value = rank, -name, -country, -`average rank`, -continent, -invRank, -intRank) %>%
mutate(
ranking = case_when(
ranking == "qs_rank" ~ "QS ranking 2018",
ranking == "ti_rank" ~ "Times Higher Education 2018",
ranking == "sh_rank" ~ "Shanghai ranking 2017",
)) %>%
write_csv("input/threeRtop50_long.csv", na ='')
## from the excel file with the fees get the country names for DW
rankFees <- read_xlsx("input/University fees.xlsx") %>%
select(-country, -Column1, -Column2, -continent, -intRank, -rankGroup) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric())
bind_cols(
rankFees,
countryTranslation(rankFees$iso2, output = c("EN", "DE", "FR", "IT", "ES", "PT","RU", "ZH", "JA","AR"))
) %>%
select(-code, -iso2) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric()) %>%
select(name, rank, Fees, qs_rank, ti_rank, sh_rank, everything()) %>%
write_csv("input/threeRtop50_fees_dw.csv", na = '-')
setwd("~/swissinfo/2018_04_17_universityRanking")
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
threeRtop
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
# # UCL fix
threeRtop[which(threeRtop$name == 'UCL'),'ti_rank'] <- 16
threeRtop
threeRtop <- read_csv("data/threeRanking_merged_post.csv")
# # UCL fix
threeRtop[which(threeRtop$name == 'UCL'),'ti_rank'] <- 16
threeRtop %<>%
mutate(
sum3R = ifelse(is.na(qs_rank), 0, qs_rank)  + ifelse(is.na(ti_rank), 0, ti_rank)  + ifelse(is.na(sh_rank), 0, sh_rank),
nonNA3R = is.na(qs_rank) + is.na(ti_rank) + is.na(sh_rank),
rank = sum3R / (3-nonNA3R)
) %>%
arrange(rank)
# reformat country name, label geo location (region)
threeRtop %<>%
mutate(
iso2 = countrycode(country, "country.name", "iso2c"),
country = countrycode(iso2, "iso2c", "country.name.en"),
region = countrycode(iso2, "iso2c", "region"),
continent = countrycode(iso2, "iso2c", "continent"),
invRank = 1/ rank,
intRank = round(rank),
rankGroup = cut(rank, breaks = c(0, 50, 100, 200, 300, 400, 500),
labels = c(' 0-50', ' 50-100', '100-200', '200-300', '300-400', '400-500'))
) %>%
select(-sum3R, -nonNA3R, -qs_key, -ti_key, -sh_key) %>%
# rename region
mutate(
region = case_when(
region == 'Eastern Asia' ~ 'East Asia',
region == 'Northern Africa' ~ 'North Africa',
region == 'Northern America' ~ 'North America',
region == 'South-Eastern Asia' ~ 'South East Asia' ,
region == 'Southern Asia' ~ 'South Asia' ,
region == 'Western Asia' ~ 'Middle East',
T ~ region
),
country = case_when(
country == 'United States of America' ~ 'USA',
country == 'United Kingdom of Great Britain and Northern Ireland' ~ 'UK',
T ~ country
)
)
threeRtop_500 <- threeRtop %>%
head(500)
# flourish export
threeRtop_500 %>%
mutate(keylocation = str_c("loc_", 1:n())) %>%
select(-lon, -lat)  %>%
write_csv("input/threeRtop500.csv", na ='')
# flourish geo lon lat data file
threeRtop_500 %>%
mutate(keylocation = str_c("loc_", 1:n())) %>%
select(lon, lat, keylocation, country, region, name) %>%
write_csv("input/threeRtop500_lonLat.csv")
# DW export table
threeRtop_500 %>%
write_csv("input/threeRtop500_dw.csv", na = '-')
# DW export map
threeRtop_500 %>%
select(lat, lon, everything(), -continent, -region, -intRank, -rankGroup) %>%
filter(!is.na(lon)) ->
threeRtop_500_map
bind_cols(
threeRtop_500_map,
countryTranslation(threeRtop_500_map$iso2, output = c("EN", "DE", "FR", "IT", "ES", "PT","RU", "ZH", "JA","AR"))
) %>%
select(-country, -iso2, -code) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric()) %>%
write_csv("input/threeRtop500_dwMap.csv", na = '-')
# make it long
threeRtop %>%
filter(!is.na(qs_rank), !is.na(ti_rank), !is.na(sh_rank)) %>%
head(50) %>%
select(-lon, -lat, -iso2, -region, invRank, -rankGroup) %>%
rename(`average rank` = rank) %>%
gather(key = ranking, value = rank, -name, -country, -`average rank`, -continent, -invRank, -intRank) %>%
mutate(
ranking = case_when(
ranking == "qs_rank" ~ "QS ranking 2018",
ranking == "ti_rank" ~ "Times Higher Education 2018",
ranking == "sh_rank" ~ "Shanghai ranking 2017",
)) %>%
write_csv("input/threeRtop50_long.csv", na ='')
## from the excel file with the fees get the country names for DW
rankFees <- read_xlsx("input/University fees.xlsx") %>%
select(-country, -Column1, -Column2, -continent, -intRank, -rankGroup) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric())
bind_cols(
rankFees,
countryTranslation(rankFees$iso2, output = c("EN", "DE", "FR", "IT", "ES", "PT","RU", "ZH", "JA","AR"))
) %>%
select(-code, -iso2) %>%
mutate(rank = formatC(rank, digits = 2) %>% as.numeric()) %>%
select(name, rank, Fees, qs_rank, ti_rank, sh_rank, everything()) %>%
write_csv("input/threeRtop50_fees_dw.csv", na = '-')
1/13
